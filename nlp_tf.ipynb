{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3dR+PP/LnmSS9hLtb78jW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash119/learn_tensorflow/blob/main/nlp_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Character RNN"
      ],
      "metadata": {
        "id": "fJSRDkd4hY15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Training Dataset"
      ],
      "metadata": {
        "id": "39oxR1Bshp2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "filepath= tf.keras.utils.get_file(\"shakespeare_txt\",\n",
        "                                  origin=\"https://homl.info/shakespeare\")\n",
        "with open(filepath) as fp:\n",
        "  shakespeare_tex= fp.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSfY-hdahuXV",
        "outputId": "76d049df-088c-4f9d-c97a-c0d250fe6aaa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shakespeare_tex[:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHaypQ-0iKRc",
        "outputId": "1073ce40-8760-4585-d1a3-c825031e7d8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Text Vectorization"
      ],
      "metadata": {
        "id": "VQGtDeVbidUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform character text vectorization\n",
        "text_vec_layer= tf.keras.layers.TextVectorization(split=\"character\",\n",
        "                                                  standardize=\"lower\")\n",
        "text_vec_layer.adapt([shakespeare_tex])"
      ],
      "metadata": {
        "id": "Zo-g_gUiimTf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence=\" I am here to learn nlp\"\n",
        "print(len(sample_sentence))\n",
        "## Vectorize the sample sentence\n",
        "text_vec_layer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yua72JxejsLR",
        "outputId": "3fcf0f0a-c5f8-4689-827b-e2c342e4dcc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 23), dtype=int64, numpy=\n",
              "array([[ 2,  7,  2,  6, 16,  2,  8,  3, 10,  3,  2,  4,  5,  2, 13,  3,\n",
              "         6, 10, 11,  2, 11, 13, 24]])>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens= text_vec_layer([shakespeare_tex])[0]\n",
        "# Print some text from original text\n",
        "print(f\" Original Text : {shakespeare_tex[:80]} \")\n",
        "# Print the vectorized text\n",
        "print(f\" Vectorized tokens: {tokens[:80]}\")\n",
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cLpUhChkq77",
        "outputId": "5f66e480-ed7c-4fe7-b07f-b1ae7fa0064d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original Text : First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak. \n",
            " Vectorized tokens: [21  7 10  9  4  2 20  7  4  7 37  3 11 25 12 23  3 21  5 10  3  2 18  3\n",
            "  2 24 10  5 20  3  3 14  2  6 11 17  2 21 15 10  4  8  3 10 19  2  8  3\n",
            "  6 10  2 16  3  2  9 24  3  6 26 28 12 12  6 13 13 25 12  9 24  3  6 26\n",
            " 19  2  9 24  3  6 26 28]\n",
            "1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Unique token characters in vocabulary\n",
        "chars_in_vocab= text_vec_layer.get_vocabulary()\n",
        "top_5_chars= chars_in_vocab[:5]\n",
        "bottom_5_chars= chars_in_vocab[-5:]\n",
        "print(f\" Number of characters in vocab :{text_vec_layer.vocabulary_size()}\")\n",
        "print(f\" top 5 common tokens: {top_5_chars}\")\n",
        "print(f\" bottom 5 common tokens: {bottom_5_chars}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDgnTKtVo0bE",
        "outputId": "5ef0d6e1-a1c2-466b-8161-e10f852ce5d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Number of characters in vocab :41\n",
            " top 5 common tokens: ['', '[UNK]', ' ', 'e', 't']\n",
            " bottom 5 common tokens: ['x', 'z', '3', '&', '$']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokens -= 2 # Remove the 0 (pad) and 1(UNK) token\n",
        "n_tokens = text_vec_layer.vocabulary_size() - 2\n",
        "dataset_size= len(tokens)\n",
        "print(f\" dataset size : {len(tokens)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIwIfx36qHDl",
        "outputId": "e88d0a2d-ddd3-4232-a738-e122f47dfc48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " dataset size : 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perpare Dataset"
      ],
      "metadata": {
        "id": "Sv3sRJuT2TSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "  ds= tf.data.Dataset.from_tensor_slices(sequence)\n",
        "  ds= ds.window(length+1, shift=1, drop_remainder=True)\n",
        "  ds= ds.flat_map(lambda window_ds: window_ds.batch(length+1))\n",
        "  if shuffle:\n",
        "    ds= ds.shuffle(buffer_size=100_000,seed=seed)\n",
        "  ds= ds.batch(batch_size)\n",
        "  return ds.map(lambda window: (window[:, :-1], window[:,1:])).prefetch(1)\n"
      ],
      "metadata": {
        "id": "isjnUF8s2Y7z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length= 100\n",
        "tf.random.set_seed(42)\n",
        "train_set= to_dataset(tokens[:100_000],length=length\n",
        "                      , shuffle=True,seed=42)\n",
        "valid_set= to_dataset(tokens[1_000_000:1_060_000],length=length)\n",
        "test_set= to_dataset(tokens[1_600_000:],length=length)"
      ],
      "metadata": {
        "id": "RFnjyqir3ZcP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Embedding using an Embedding Layer"
      ],
      "metadata": {
        "id": "Gi3Rbr790nSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=n_tokens\n",
        "                                            ,output_dim=16\n",
        "                                            ,input_length=length)\n",
        "embedding_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yKSKD8b1MeZ",
        "outputId": "57f3405d-dcfe-44c0-c133-fc80451b0123"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.embedding.Embedding at 0x7b6b20345390>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentenc= \" I am here to learn NLP\"\n",
        "print(f\" Sample Sentenc : {sample_sentence}\")\n",
        "tokens_of_sample_sentence= text_vec_layer(sample_sentence)\n",
        "print(f\" length of tokens from TextVectorizer for sample sentence: {len(tokens_of_sample_sentence)}\")\n",
        "embeddings_of_sample_sentence= embedding_layer(tokens_of_sample_sentence)\n",
        "print(f\" Shape of Embeddings from embeding layer for sample sentence: {embeddings_of_sample_sentence.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duhtKwwT4I-e",
        "outputId": "2566b645-b5bb-4d1f-b52c-48806a2e37e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sample Sentenc :  I am here to learn nlp\n",
            " length of tokens from TextVectorizer for sample sentence: 23\n",
            " Shape of Embeddings from embeding layer for sample sentence: (23, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Training the Char-RNN model\n"
      ],
      "metadata": {
        "id": "ivQ_Nl1D45gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_model= tf.keras.Sequential([\n",
        "    embedding_layer\n",
        "    ,tf.keras.layers.GRU(128,return_sequences=True)\n",
        "    ,tf.keras.layers.Dense(n_tokens,activation=\"softmax\")\n",
        "])\n",
        "\n",
        "char_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy\n",
        "                   ,optimizer=tf.keras.optimizers.Nadam()\n",
        "                   ,metrics=['accuracy'])\n",
        "model_ckpt= tf.keras.callbacks.ModelCheckpoint(\"my_shakespeare_model\"\n",
        "                                               ,monitor=\"val_accuracy\"\n",
        "                                               ,save_best_only=True)\n",
        "history= char_model.fit(train_set\n",
        "                        ,validation_data=valid_set\n",
        "                        ,epochs=1\n",
        "                        ,callbacks=[model_ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zxmDvFQn6j3X",
        "outputId": "672504b8-fc74-42b6-d5f8-2a9a69fa6197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r      1/Unknown - 25s 25s/step - loss: 3.6633 - accuracy: 0.0131"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-18f8daaa4fc6>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                \u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                ,save_best_only=True)\n\u001b[0;32m---> 13\u001b[0;31m history= char_model.fit(train_set\n\u001b[0m\u001b[1;32m     14\u001b[0m                         \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/embedding/embedding_lookup' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-17-18f8daaa4fc6>\", line 13, in <cell line: 13>\n      history= char_model.fit(train_set\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/core/embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_2/embedding/embedding_lookup'\nindices[26,75] = 39 is not in [0, 39)\n\t [[{{node sequential_2/embedding/embedding_lookup}}]] [Op:__inference_train_function_5521]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweet Categorization\n",
        "Text-based Tweets about natural disasters."
      ],
      "metadata": {
        "id": "fr12PiLb6XB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and unzip the data"
      ],
      "metadata": {
        "id": "hpN06LnC_uUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "import zipfile\n",
        "import os\n",
        "def unzip_data(file, remove_zip_file=True):\n",
        "  \"\"\"\n",
        "  unizp the zipped file and optionally removes the original zipefile\n",
        "  \"\"\"\n",
        "  zipref= zipfile.ZipFile(file)\n",
        "  zipref.extractall()\n",
        "  os.remove(file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QL_32Ov8hlm",
        "outputId": "320f5e8d-7fce-451b-c491-bc4f4f86fd49"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-19 06:19:56--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.79.128, 108.177.96.128, 108.177.119.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.79.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  1.27MB/s    in 0.5s    \n",
            "\n",
            "2023-08-19 06:19:57 (1.27 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"/content/nlp_getting_started.zip\")"
      ],
      "metadata": {
        "id": "NNmlqoym9fqF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data as pandas dataframe"
      ],
      "metadata": {
        "id": "4oH_m4Uj9lLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df= pd.read_csv(\"/content/train.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "UQ7-hIcZ_3Ex",
        "outputId": "4617d237-0ab5-4d58-945a-5ae1accf32ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ba2d12c-8a39-46ff-9c0c-5caa3acb1b12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ba2d12c-8a39-46ff-9c0c-5caa3acb1b12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ba2d12c-8a39-46ff-9c0c-5caa3acb1b12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ba2d12c-8a39-46ff-9c0c-5caa3acb1b12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29a0835c-6e45-4db9-87fa-712befe11cc5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29a0835c-6e45-4db9-87fa-712befe11cc5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29a0835c-6e45-4db9-87fa-712befe11cc5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the dataset into train and test"
      ],
      "metadata": {
        "id": "el-HANonACPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# the ouput tuple is of the format (X_train, X_valid, y_train, y_valid)\n",
        "train_sent, val_sent,train_target,val_target= train_test_split(train_df[\"text\"].to_numpy()\n",
        "                                                           ,train_df[\"target\"].to_numpy()\n",
        "                                                           ,test_size=0.1\n",
        "                                                           ,random_state=42)\n",
        "print(f\"\"\"\n",
        "training feature rows : {len(train_sent)}\n",
        "training target rows : {len(train_target)}\n",
        "validation feature rows: {len(val_target)}\n",
        "validation target rows: {len(val_target)}\n",
        "      \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usDnWU3iAYfo",
        "outputId": "a16f44ff-fb3a-4a8e-ed79-5d36c2eb44eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "training feature rows : 6851\n",
            "training target rows : 6851\n",
            "validation feature rows: 762\n",
            "validation target rows: 762\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Vectorization\n",
        "Convert the text to numbers"
      ],
      "metadata": {
        "id": "7TmoLsKSBP5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer= tf.keras.layers.TextVectorization(max_tokens=max_vocab_length\n",
        "                                                  ,output_sequence_length=max_length\n",
        "                                                  )\n",
        "text_vectorizer.adapt(train_sent)\n",
        "\n",
        "import random\n",
        "random_sentence= random.choice(train_sent)\n",
        "print(f\" Random Sentence from training set :\\n {random_sentence}\\n\")\n",
        "vectorized_random_sentence= text_vectorizer(random_sentence)\n",
        "print(f\" Vectorized form of random sentence : \\n { vectorized_random_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u92H27GFCz1q",
        "outputId": "a1b31e49-94e0-4203-b8af-248aca17f463"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Random Sentence from training set :\n",
            " Shed innocent blood of their sons and daughters and the land was polluted Psalms 106:38  Help stop the sin of abortion.\n",
            "\n",
            " Vectorized form of random sentence : \n",
            " [4624 5325  348    6  114 4558    7 3064    7    2  549   23 9695 9502\n",
            "    1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Size of the vocabulary : {text_vectorizer.vocabulary_size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRghQ8MTEym-",
        "outputId": "375aefc3-0388-48b9-fc01-aeb6bbd483ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Size of the vocabulary : 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Metrics function\n",
        "Function to evaluate a model accuracy, f1 ,precision, recall\n"
      ],
      "metadata": {
        "id": "b0M6_XzrQ9cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "eqjTvbrIRSfB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset"
      ],
      "metadata": {
        "id": "avMvnT33HhT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes ( Baseline )"
      ],
      "metadata": {
        "id": "Gp567_H4NMq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0= Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer())\n",
        "    ,(\"clf\",MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "model_0.fit(train_sent,train_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "shQVlw9jNcBh",
        "outputId": "d8d260b2-8462-4fb1-ed15-9bde74cbbddc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Score the model\n",
        "model_0_results= model_0.score(val_sent,val_target)\n",
        "print(f\" Accuracy from baseline model : {model_0_results*100:.3f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edaC_JyWOFUA",
        "outputId": "2dafc9dd-1e70-4625-a21f-de0d00968bf0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy from baseline model : 77.822%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_0_preds= model_0.predict(val_sent)\n",
        "\n",
        "print(f\" Target Labels : {val_target[:10]}\")\n",
        "import numpy as np\n",
        "\n",
        "np.isclose(val_target[:10],model_0_preds[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK917jtuPV64",
        "outputId": "6dba4524-cd21-49f2-fbbb-c860b199e094"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Target Labels : [1 0 1 0 0 0 1 1 0 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True, False,  True,  True,  True, False, False,  True,\n",
              "        True])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(val_target,model_0_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e32mDIPfRhcS",
        "outputId": "60904a67-4b5e-4d94-9920-1ae4e134fd14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.82152230971128,\n",
              " 'precision': 0.792992256322435,\n",
              " 'recall': 0.7782152230971129,\n",
              " 'f1': 0.7703527809038113}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dense Model (Model 1)\n"
      ],
      "metadata": {
        "id": "aHo_bTA_OhKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Sequential API"
      ],
      "metadata": {
        "id": "vw72lRMU5SaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embedding Layer\n",
        "This will create learnable embeddings for our text"
      ],
      "metadata": {
        "id": "iwr4yFSyFuHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_dim= vocabulary size\n",
        "# output_dim= size of the vectors for each element in vocabulary\n",
        "# input_length= Length of input sequences, when it is constant\n",
        "embedding_layer= tf.keras.layers.Embedding(input_dim=max_vocab_length\n",
        "                                           ,output_dim=128\n",
        "                                           ,input_length=max_length)\n",
        "\n",
        "import random\n",
        "random_sentence= random.choice(train_sent)\n",
        "print(f\" Random Sentence from training set :\\n {random_sentence}\")\n",
        "\n",
        "vectorized_random_sentence= text_vectorizer(random_sentence)\n",
        "print(f\" \\nVectorized form of random sentence : \\n { vectorized_random_sentence}\")\n",
        "\n",
        "embeddings_of_sample_sentence= embedding_layer(vectorized_random_sentence)\n",
        "print(f\" \\nEmbeddings random sentence : \\n { embeddings_of_sample_sentence}\")\n",
        "print(f\" \\n Shape of embeddings : {embeddings_of_sample_sentence.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGE8qwHlGMVN",
        "outputId": "5cf74789-71a5-4cb2-fb77-0e3c16d15d06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Random Sentence from training set :\n",
            " The thunder shook my house woke my sister and made car alarms go off ????\n",
            " \n",
            "Vectorized form of random sentence : \n",
            " [   2  281 3420   13  290 1580   13 1766    7  286  120 4151  111   93\n",
            "    0]\n",
            " \n",
            "Embeddings random sentence : \n",
            " [[-0.01007521 -0.02513694  0.04380209 ...  0.03106899  0.0045206\n",
            "  -0.0080335 ]\n",
            " [ 0.04133676 -0.02438538 -0.01256455 ... -0.004109   -0.00314444\n",
            "   0.02058831]\n",
            " [-0.01298745 -0.02286965 -0.0107521  ...  0.04048712  0.03673976\n",
            "  -0.02227726]\n",
            " ...\n",
            " [ 0.01340124 -0.03621493 -0.046087   ...  0.0178371  -0.01586359\n",
            "  -0.04420078]\n",
            " [ 0.04104669  0.00935958  0.0095611  ...  0.01601711  0.02357067\n",
            "   0.00550453]\n",
            " [-0.04736855  0.04581997 -0.02523478 ...  0.04827455  0.04164732\n",
            "  -0.00416782]]\n",
            " \n",
            " Shape of embeddings : (15, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build , Train & Evaluate Model"
      ],
      "metadata": {
        "id": "PiW-GMj7FSYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "# Build the model using Sequential API\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "model_1_seq= tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,),dtype=\"string\")\n",
        "    ,text_vectorizer\n",
        "    ,embedding_layer\n",
        "    ,layers.GlobalAveragePooling1D()\n",
        "    ,layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_1_seq.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                    ,optimizer=tf.keras.optimizers.Adam()\n",
        "                    ,metrics=[\"accuracy\"])\n",
        "model_1_seq.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHQidne5RzEn",
        "outputId": "680c256c-2d8d-43f6-bdfb-7c9a2484390f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_1_seq_hist= model_1_seq.fit(train_sent,train_target\n",
        "                                  ,validation_data=(val_sent,val_target)\n",
        "                                  ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HomSrhYETPTg",
        "outputId": "c65cb723-25ec-4067-fd30-dfa64bb3b865"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 11s 39ms/step - loss: 0.6114 - accuracy: 0.6887 - val_loss: 0.5413 - val_accuracy: 0.7625\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.4395 - accuracy: 0.8170 - val_loss: 0.4831 - val_accuracy: 0.7887\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 7s 31ms/step - loss: 0.3451 - accuracy: 0.8622 - val_loss: 0.4749 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_1_seq.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOcWFhwOBTt3",
        "outputId": "8601ee7e-f065-4123-c3a0-a8cd92d637c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47487494349479675, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do Prediction\n",
        "model_1_seq_preds_proba= model_1_seq.predict(val_sent)\n",
        "model_1_seq_preds= tf.squeeze(tf.round(model_1_seq_preds_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adlRQcEABtVU",
        "outputId": "adca409b-9859-41e3-e60b-bfa18429e2f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(y_true=val_target\n",
        "                  ,y_pred=model_1_seq_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl-jz3z1B3Kx",
        "outputId": "894e8051-b6e9-4930-9a10-4443ec0d55d3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'precision': 0.7897763444463061,\n",
              " 'recall': 0.7874015748031497,\n",
              " 'f1': 0.7844490087488502}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functional API"
      ],
      "metadata": {
        "id": "HZ6kN23XVxz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embedding Layer\n",
        "This will create learnable embeddings for our text"
      ],
      "metadata": {
        "id": "cbGgREVUFdfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_dim= vocabulary size\n",
        "# output_dim= size of the vectors for each element in vocabulary\n",
        "# input_length= Length of input sequences, when it is constant\n",
        "embedding_layer= tf.keras.layers.Embedding(input_dim=max_vocab_length\n",
        "                                           ,output_dim=128\n",
        "                                           ,input_length=max_length)\n",
        "\n",
        "import random\n",
        "random_sentence= random.choice(train_sent)\n",
        "print(f\" Random Sentence from training set :\\n {random_sentence}\")\n",
        "\n",
        "vectorized_random_sentence= text_vectorizer(random_sentence)\n",
        "print(f\" \\nVectorized form of random sentence : \\n { vectorized_random_sentence}\")\n",
        "\n",
        "embeddings_of_sample_sentence= embedding_layer(vectorized_random_sentence)\n",
        "print(f\" \\nEmbeddings random sentence : \\n { embeddings_of_sample_sentence}\")\n",
        "print(f\" \\n Shape of embeddings : {embeddings_of_sample_sentence.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a0fae5-23f4-4870-e841-9e3701fb02c1",
        "id": "QoMs9hbWFdf0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Random Sentence from training set :\n",
            " The fact that the atomic bombs were called 'Little Boy' and 'Fat man' says a lot about the mentality that went into the attack.\n",
            " \n",
            "Vectorized form of random sentence : \n",
            " [   2 1299   16    2  214 1027   68  778  245  332    7 1533   96  273\n",
            "    3]\n",
            " \n",
            "Embeddings random sentence : \n",
            " [[-0.0386566   0.0039768  -0.04148995 ...  0.02769985 -0.02348822\n",
            "  -0.02563067]\n",
            " [-0.01421382  0.03974347 -0.03256079 ... -0.03627352  0.02616512\n",
            "  -0.00466117]\n",
            " [ 0.01765224 -0.01619581  0.04560056 ... -0.02538377  0.0025444\n",
            "  -0.00897261]\n",
            " ...\n",
            " [-0.005717   -0.04298306  0.0079469  ...  0.00591335 -0.02090634\n",
            "  -0.04462837]\n",
            " [-0.03524525 -0.01381073  0.0404788  ...  0.00683331 -0.04372438\n",
            "  -0.04445002]\n",
            " [ 0.03734577 -0.04282352  0.02210995 ... -0.04578521  0.0003613\n",
            "   0.01329196]]\n",
            " \n",
            " Shape of embeddings : (15, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build , Train, Evaluate Model"
      ],
      "metadata": {
        "id": "tvj6ROjyFlJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs= layers.Input(shape=(1,), dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= embedding_layer(x)\n",
        "x= layers.GlobalAveragePooling1D(name=\"globalavgpooling\")(x)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\",name=\"dense\")(x)\n",
        "model_1_func= tf.keras.Model(inputs=inputs\n",
        "                             ,outputs= outputs\n",
        "                             ,name=\"dense_model_1_func\")\n",
        "\n",
        "model_1_func.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                     ,optimizer=tf.keras.optimizers.Adam()\n",
        "                     ,metrics=[\"accuracy\"])\n",
        "\n",
        "model_1_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_MIeeD35hF5",
        "outputId": "e120e889-401f-4c87-ccb0-426e77abbc52"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"dense_model_1_func\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " globalavgpooling (GlobalAve  (None, 128)              0         \n",
            " ragePooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_func_hist= model_1_func.fit(train_sent,train_target\n",
        "                                    ,validation_data=(val_sent,val_target)\n",
        "                                    ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmxjfelq8fC2",
        "outputId": "38a7c7b1-73bb-4c20-ad13-d70e28834d51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 5s 18ms/step - loss: 0.6093 - accuracy: 0.6965 - val_loss: 0.5402 - val_accuracy: 0.7651\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.4388 - accuracy: 0.8178 - val_loss: 0.4829 - val_accuracy: 0.7913\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3446 - accuracy: 0.8625 - val_loss: 0.4748 - val_accuracy: 0.7887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_1_func.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20904c9-42e4-423f-b999-b40d57ffeea2",
        "id": "TkU1xrxtCqDl"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47482219338417053, 0.7887139320373535]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_func_proba= model_1_func.predict(val_sent)\n",
        "model_1_func_preds= tf.squeeze(tf.round(model_1_func_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WOOrR_KCu2o",
        "outputId": "c320a1d5-94b8-4ab4-f61f-88f1e939a7ec"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(y_true=val_target,y_pred=model_1_func_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwq5_OkwC_Xd",
        "outputId": "f3ab8c02-d035-426c-c8fe-02945f819837"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.87139107611549,\n",
              " 'precision': 0.7913065706940227,\n",
              " 'recall': 0.7887139107611548,\n",
              " 'f1': 0.785702921924679}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recurrent Neural Network (LSTM)"
      ],
      "metadata": {
        "id": "JXW5SEmVDID1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sequential API"
      ],
      "metadata": {
        "id": "OEvCbi19Dz_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embedding Layer"
      ],
      "metadata": {
        "id": "RHl5ILPqGG3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "# Since the embeddings are learnable we will have to create the embedding for every\n",
        "# model\n",
        "embedding_layer_rnn= layers.Embedding(input_dim=max_vocab_length\n",
        "                                      ,output_dim=128\n",
        "                                      ,input_length=max_length)"
      ],
      "metadata": {
        "id": "_vGb8z34EQjx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build, Train, Evaluate the model"
      ],
      "metadata": {
        "id": "DOolVcRxHNOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "tf.random.set_seed(42)\n",
        "model_2_seq= tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,),dtype=\"string\")\n",
        "    ,text_vectorizer\n",
        "    ,embedding_layer_rnn\n",
        "    ,layers.LSTM(64)\n",
        "    ,layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_2_seq.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                    ,optimizer=tf.keras.optimizers.Adam()\n",
        "                    ,metrics=[\"accuracy\"])\n",
        "model_2_seq.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfwSjAlREEeU",
        "outputId": "f2eec872-648e-4681-99f9-51e2531c0ccb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_2_seq_hist= model_2_seq.fit(train_sent,train_target\n",
        "                                  ,validation_data=(val_sent,val_target)\n",
        "                                  ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G47IjhSOGxH3",
        "outputId": "440002e7-4f60-4d81-a2c5-7d5f0424e6d6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 11s 34ms/step - loss: 0.5139 - accuracy: 0.7450 - val_loss: 0.4660 - val_accuracy: 0.7913\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.3155 - accuracy: 0.8720 - val_loss: 0.5228 - val_accuracy: 0.7808\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 7s 30ms/step - loss: 0.2183 - accuracy: 0.9206 - val_loss: 0.5257 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_2_seq.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g204aj8-HoQi",
        "outputId": "c98f9939-e683-40af-ec63-e71ceee17680"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7703\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5256800651550293, 0.7703412175178528]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do prediction\n",
        "model_2_pred_proba= model_2_seq.predict(val_sent)\n",
        "model_2_preds= tf.squeeze(tf.round(model_2_pred_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmXr67czHn1Q",
        "outputId": "51b4d43d-5967-451b-fa4e-1dd91696a6c7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "calculate_results(y_true=val_target,y_pred=model_2_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EErwZDFdIB7u",
        "outputId": "b0971390-ede0-46bc-cbd9-c5561f8c0f70"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'precision': 0.7707448774088915,\n",
              " 'recall': 0.7703412073490814,\n",
              " 'f1': 0.7680081280884467}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functional API"
      ],
      "metadata": {
        "id": "POI7osHoD_d1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embedding Layer"
      ],
      "metadata": {
        "id": "GmILdkNtISDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer_rnn2= layers.Embedding(input_dim=max_vocab_length\n",
        "                                       ,output_dim=128\n",
        "                                       ,input_length=25)"
      ],
      "metadata": {
        "id": "-HSMUFqsIRkb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build, Train & Evaluate"
      ],
      "metadata": {
        "id": "XWRaw0aJIW17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Build the model\n",
        "tf.random.set_seed(42)\n",
        "inputs= layers.Input(shape=(1,),dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= embedding_layer_rnn2(x)\n",
        "x= layers.LSTM(64)(x)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_2_func= tf.keras.Model(inputs= inputs\n",
        "                             ,outputs=outputs\n",
        "                             ,name=\"model_2_rnn\")\n",
        "\n",
        "model_2_func.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                     ,optimizer=tf.keras.optimizers.Adam()\n",
        "                     ,metrics=[\"accuracy\"])\n",
        "\n",
        "model_2_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6FSgpHUEB-N",
        "outputId": "64793e38-e04c-4d4c-e225-17067f4c1d97"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_rnn\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_2_func_hist= model_2_func.fit(train_sent,train_target\n",
        "                                    ,validation_data=(val_sent,val_target)\n",
        "                                    ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YmMDxokJqgf",
        "outputId": "6e697997-d706-4adb-cb49-4b18b14251da"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 11s 41ms/step - loss: 0.5120 - accuracy: 0.7475 - val_loss: 0.4625 - val_accuracy: 0.7913\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 7s 34ms/step - loss: 0.3144 - accuracy: 0.8727 - val_loss: 0.5273 - val_accuracy: 0.7874\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 7s 34ms/step - loss: 0.2155 - accuracy: 0.9209 - val_loss: 0.5357 - val_accuracy: 0.7808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_2_func.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf9ceC8XKTxQ",
        "outputId": "c9d2a181-1e76-486e-825d-39dcc966096a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.7808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5356898903846741, 0.7808399200439453]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "model_2_func_preds_proba= model_2_func.predict(val_sent)\n",
        "model_2_func_preds= tf.squeeze(tf.round(model_2_func_preds_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiOnZeluKYnJ",
        "outputId": "f9723fe2-1bc6-4e60-b558-7a07ae952749"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "calculate_results(y_true=val_target,y_pred=model_2_func_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9U2JejKnQU",
        "outputId": "8b04e23a-aee8-41d8-899d-4089f835dfc4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.08398950131233,\n",
              " 'precision': 0.7828035148534721,\n",
              " 'recall': 0.7808398950131233,\n",
              " 'f1': 0.7778748302844208}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X7PxzRIcKsso"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recurrent Neural Network (GRU)"
      ],
      "metadata": {
        "id": "k6RpBDE2L-c6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sequential API"
      ],
      "metadata": {
        "id": "5nFFTRLAL-c7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embedding Layer"
      ],
      "metadata": {
        "id": "uYgvLKIlL-c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "# Since the embeddings are learnable we will have to create the embedding for every\n",
        "# model\n",
        "embedding_layer_gru= layers.Embedding(input_dim=max_vocab_length\n",
        "                                      ,output_dim=128\n",
        "                                      ,input_length=max_length)"
      ],
      "metadata": {
        "id": "WujTXKauL-c8"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build, Train, Evaluate the model"
      ],
      "metadata": {
        "id": "RBk6lYOLL-c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "tf.random.set_seed(42)\n",
        "model_3_seq= tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,),dtype=\"string\")\n",
        "    ,text_vectorizer\n",
        "    ,embedding_layer_gru\n",
        "    ,layers.GRU(64)\n",
        "    ,layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_3_seq.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                    ,optimizer=tf.keras.optimizers.Adam()\n",
        "                    ,metrics=[\"accuracy\"])\n",
        "model_3_seq.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb0e95a-5db8-4051-8dd8-0d1866bc7f51",
        "id": "SZcN4KFjL-c9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_3_seq_hist= model_3_seq.fit(train_sent,train_target\n",
        "                                  ,validation_data=(val_sent,val_target)\n",
        "                                  ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876189bc-3550-473c-a2eb-37733f3e5ec7",
        "id": "HdVCbYTIL-c-"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 11s 36ms/step - loss: 0.5291 - accuracy: 0.7297 - val_loss: 0.4674 - val_accuracy: 0.7979\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.3168 - accuracy: 0.8713 - val_loss: 0.5162 - val_accuracy: 0.7848\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.2184 - accuracy: 0.9165 - val_loss: 0.5215 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_3_seq.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d467d0a3-46e9-4ccb-b8c4-ca52ff21b7b8",
        "id": "kPxvoSXCL-c_"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.5215 - accuracy: 0.7795\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5214547514915466, 0.7795275449752808]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do prediction\n",
        "model_3_pred_proba= model_3_seq.predict(val_sent)\n",
        "model_3_preds= tf.squeeze(tf.round(model_3_pred_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a606ff7-6937-4500-c071-d8f087f510a3",
        "id": "4yra4oaZL-c_"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "calculate_results(y_true=val_target,y_pred=model_3_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fca0ad-0f6e-4978-bd73-8a8849ae3f41",
        "id": "sRaMfSKGL-c_"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'precision': 0.7812950247858184,\n",
              " 'recall': 0.7795275590551181,\n",
              " 'f1': 0.7766229620954818}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functional API"
      ],
      "metadata": {
        "id": "-wgdadNHL-dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embedding Layer"
      ],
      "metadata": {
        "id": "Pum1SrzNL-dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding_layer_gru2= layers.Embedding(input_dim=max_vocab_length\n",
        "                                       ,output_dim=128\n",
        "                                       ,input_length=25)"
      ],
      "metadata": {
        "id": "TFdAlvTsL-dA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build, Train & Evaluate"
      ],
      "metadata": {
        "id": "O5QnWxGDL-dB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Build the model\n",
        "tf.random.set_seed(42)\n",
        "inputs= layers.Input(shape=(1,),dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= embedding_layer_gru2(x)\n",
        "x= layers.LSTM(64)(x)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_3_func= tf.keras.Model(inputs= inputs\n",
        "                             ,outputs=outputs\n",
        "                             ,name=\"model_3_gru\")\n",
        "\n",
        "model_3_func.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                     ,optimizer=tf.keras.optimizers.Adam()\n",
        "                     ,metrics=[\"accuracy\"])\n",
        "\n",
        "model_3_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94160d4b-f088-475d-b3ec-ba037967069a",
        "id": "VLqtrD_DL-dB"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_gru\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_3_func_hist= model_3_func.fit(train_sent,train_target\n",
        "                                    ,validation_data=(val_sent,val_target)\n",
        "                                    ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5f73bd-1acb-44cc-d8d0-b6d8f8e40ff2",
        "id": "lEXRu-mDL-dB"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 11s 36ms/step - loss: 0.5140 - accuracy: 0.7459 - val_loss: 0.4627 - val_accuracy: 0.8018\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.3152 - accuracy: 0.8733 - val_loss: 0.5231 - val_accuracy: 0.7913\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 7s 31ms/step - loss: 0.2180 - accuracy: 0.9196 - val_loss: 0.5172 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_3_func.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f42ccb-64f4-42d0-e20a-d52655979f07",
        "id": "_4z9c_iUL-dC"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7703\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5172091722488403, 0.7703412175178528]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "model_3_func_preds_proba= model_3_func.predict(val_sent)\n",
        "model_3_func_preds= tf.squeeze(tf.round(model_3_func_preds_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c3ab5c-4310-4203-816f-80e57f06cd7b",
        "id": "VjflHHMuL-dC"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "calculate_results(y_true=val_target,y_pred=model_3_func_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2945d9-33f7-44bd-eddc-557555f1ad0a",
        "id": "8UD6QK4RL-dC"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'precision': 0.7721862413486815,\n",
              " 'recall': 0.7703412073490814,\n",
              " 'f1': 0.7670683933963902}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bidirectional RNN"
      ],
      "metadata": {
        "id": "znPSjkRFN3Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sequential API"
      ],
      "metadata": {
        "id": "PDwus1xgUQnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Emdedding Layer"
      ],
      "metadata": {
        "id": "rOutTcyzUvZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "embedding_layer_birnn= layers.Embedding(input_dim=max_vocab_length\n",
        "                                        ,output_dim=128\n",
        "                                        ,input_length=max_length)"
      ],
      "metadata": {
        "id": "AVR0dhR2WzUY"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Build, Train, Evaluate Model"
      ],
      "metadata": {
        "id": "2pmZreMAUu5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model_4_seq= tf.keras.Sequential([\n",
        "    layers.Input(shape=(1,),dtype=\"string\")\n",
        "    ,text_vectorizer\n",
        "    ,embedding_layer_birnn\n",
        "    ,layers.Bidirectional(layers.LSTM(64))\n",
        "    ,layers.Dense(1,activation=\"sigmoid\")\n",
        "])\n",
        "model_4_seq.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                    ,optimizer=tf.keras.optimizers.Adam()\n",
        "                    ,metrics=[\"accuracy\"])\n",
        "\n",
        "model_4_seq.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFUKJMj3XEpU",
        "outputId": "61c4206a-d2fd-4dce-edc2-96bb7776dd02"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_4_seq_hist= model_4_seq.fit(train_sent,train_target\n",
        "                                  ,validation_data=(val_sent,val_target)\n",
        "                                  ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIbvtz9JXyHc",
        "outputId": "45147fa2-48fd-4685-c5f3-ed60954c417a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 16s 51ms/step - loss: 0.5104 - accuracy: 0.7462 - val_loss: 0.4612 - val_accuracy: 0.8005\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.3134 - accuracy: 0.8716 - val_loss: 0.4928 - val_accuracy: 0.7874\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 10s 47ms/step - loss: 0.2104 - accuracy: 0.9222 - val_loss: 0.5507 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "model_4_seq.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWVnLHIHXx5N",
        "outputId": "377085c7-7b84-4a12-ba41-e5dd50965623"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step - loss: 0.5507 - accuracy: 0.7861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5507320761680603, 0.7860892415046692]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "model_4_seq_pred_proba= model_4_seq.predict(val_sent)\n",
        "model_4_seq_pred= tf.squeeze(tf.round(model_4_seq_pred_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KevR8a7_Xxpr",
        "outputId": "68278cf1-3f7b-4653-d901-6c9ae473c109"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate result\n",
        "calculate_results(y_true=val_target,y_pred=model_4_seq_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3hJBlf5Yu5B",
        "outputId": "2bca31c9-dab3-4626-86f7-1ee7be58ab8b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'precision': 0.7909099906966713,\n",
              " 'recall': 0.7860892388451444,\n",
              " 'f1': 0.7820422109103825}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functional API"
      ],
      "metadata": {
        "id": "G66h5KsjUrFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Embedding Layer"
      ],
      "metadata": {
        "id": "v_R4ySwuUsvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "embedding_layer_birnn2= layers.Embedding(input_dim=max_vocab_length\n",
        "                                        ,output_dim= 128\n",
        "                                        ,input_length=max_length)"
      ],
      "metadata": {
        "id": "siUkdePGZPBT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train, Build & Evaluate Model"
      ],
      "metadata": {
        "id": "35jlgVhwU9Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "inputs= layers.Input(shape=(1,),dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= embedding_layer_birnn2(x)\n",
        "x= layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_4_func= tf.keras.Model(inputs=inputs\n",
        "                             ,outputs=outputs\n",
        "                             ,name=\"model_4_bidirectional_birnn2\")\n",
        "\n",
        "model_4_func.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                     ,optimizer=tf.keras.optimizers.Adam()\n",
        "                     ,metrics=[\"accuracy\"])\n",
        "\n",
        "model_4_func.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WtJxrBWZQbh",
        "outputId": "5a5b769f-17fb-4f74-f12e-295d3d6a52b2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional_birnn2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 15)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model_4_func_hist= model_4_func.fit(train_sent,train_target\n",
        "                                    ,validation_data=(val_sent,val_target)\n",
        "                                    ,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuGxzxDeZQNT",
        "outputId": "b7b5d223-3a5b-44d9-8c6b-ac4fd1226e85"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "215/215 [==============================] - 16s 50ms/step - loss: 0.5123 - accuracy: 0.7432 - val_loss: 0.4619 - val_accuracy: 0.7992\n",
            "Epoch 2/3\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.3123 - accuracy: 0.8716 - val_loss: 0.4937 - val_accuracy: 0.7953\n",
            "Epoch 3/3\n",
            "215/215 [==============================] - 9s 44ms/step - loss: 0.2060 - accuracy: 0.9228 - val_loss: 0.5660 - val_accuracy: 0.7795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "model_4_func.evaluate(val_sent,val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-sqzSGQbESk",
        "outputId": "fb09eaaf-c310-4ed8-d129-17bdc1e61c46"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 7ms/step - loss: 0.5660 - accuracy: 0.7795\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5659992098808289, 0.7795275449752808]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "model_4_func_pred_proba= model_4_func.predict(val_sent)\n",
        "model_4_func_pred= tf.squeeze(tf.round(model_4_func_pred_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9MeZGqsZP_h",
        "outputId": "a1378fcd-7204-4f47-feba-d57363ad3cca"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "calculate_results(y_true=val_target,y_pred=model_4_func_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmEr9T_iZPtz",
        "outputId": "c5df17a8-44b9-4a7a-dffc-d3221b20bb5b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'precision': 0.7851161266397013,\n",
              " 'recall': 0.7795275590551181,\n",
              " 'f1': 0.7748890479599141}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOoXdrAPVBn0"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}