{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi+Z0SBePMRaR+AtYZXEYD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash119/learn_tensorflow/blob/main/learn_tf_009.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning Part 2: Fine-Tuning\n",
        "\n",
        "### What we will cover\n",
        "1. Introduce fine-tuning, a transfer learning approach to modify pre-trained layers to be more suited for our data.\n",
        "2. Using the keras Functional API\n",
        "3. Smaller dataset of faster experimentation\n",
        "4. Data Augmenetation ( how to make our training dataset more diverse without adding more data).\n",
        "5. Running a series of model experiments using our Food Vision data\n",
        "    1. Model0: A transfer learning model using Keras functional api\n",
        "    2. Model1: A feature extraction transfer learning model using 1% of the data with data augmentation\n",
        "    3. Model2: A feature extraction transfer learning model using 10% of the data with data augmentation.\n",
        "    4. Model3: A fine-tuned transfer learning model on 10% of data.\n",
        "    5. Model4: A fine-tuned transfer learning model on 100% of data.\n",
        "6. Introduce model checkpoints to save intermediate model results\n",
        "7. Compare the model experiments using tensorboard.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XB-lnnymj3tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXMf20WQnIr3",
        "outputId": "bd753614-67dc-4e27-e0c5-2d300f6fd87a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(f\" Notebook last run (end-to-end) {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfEM6d2fmO8z",
        "outputId": "3fe12e3d-ecc1-477e-f86f-c8aa797e0caf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Notebook last run (end-to-end) 2023-08-06 02:12:23.296755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(f\" Tensorflow version : {tf.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irjZ5un9moib",
        "outputId": "6170fcf9-e9ac-4d8d-fdec-1f577badc0a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Tensorflow version : 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_functions.py\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curve(history):\n",
        "  \"\"\"\n",
        "    Plots the loss and accuracy curve for training and validation metrics\n",
        "    Args:\n",
        "      history(A History object):\n",
        "\n",
        "  \"\"\"\n",
        "  epochs= range(len(history.history[\"loss\"]))\n",
        "  loss= history.history[\"loss\"]\n",
        "  val_loss= history.history[\"accuracy\"]\n",
        "\n",
        "  plt.plot(loss,epochs,label=\"Train loss\")\n",
        "  plt.plot(val_loss,epochs,label=\"Validation loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend()\n",
        "\n",
        "  ## Plot Accuracy\n",
        "  plt.figure()\n",
        "  accuracy= history.history[\"accuracy\"]\n",
        "  val_accuracy= history.history[\"val_accuracy\"]\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend();\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3Kp5Fm6mvwN",
        "outputId": "459fcf6b-5ab1-4ccd-c1de-cf7f733a7cc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helper_functions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Download data and unzip it\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "424j0L0Ps0Uc",
        "outputId": "66393aa1-201d-4269-c954-2bd35482de34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-06 02:12:35--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.163.128, 142.251.167.128, 142.251.16.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.163.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  78.4MB/s    in 2.1s    \n",
            "\n",
            "2023-08-06 02:12:37 (78.4 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_functions.py\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "def unzip_data(zipped_file,remove_src_zip=True):\n",
        "  \"\"\"\n",
        "    Takes a zipped file and unzips it.Removes the source zipfile.\n",
        "  \"\"\"\n",
        "  zip_ref= zipfile.ZipFile(zipped_file,\"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "  os.remove(zipped_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfiiyruOuXSp",
        "outputId": "dedcb84e-d8e1-4d9d-804c-437f7a29a80b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_functions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import unzip_data\n",
        "unzip_data(\"/content/10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "EuDnBw6hvHYz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r \"/content/__MACOSX\""
      ],
      "metadata": {
        "id": "HqqNMiRavLZo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir= \"/content/10_food_classes_10_percent\""
      ],
      "metadata": {
        "id": "7J1x3Tx3wejJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile -a helper_functions.py\n",
        "\n",
        "def walk_through_dir(data_dir):\n",
        "  for dirpath,dirnames,filenames in os.walk(data_dir):\n",
        "    print(f\" There are {len(filenames)} images and {len(dirnames)} folder at {dirpath}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LEN1OuKwOyJ",
        "outputId": "a7d615cd-aa76-48ab-9d21-1673a4ab9d6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appending to helper_functions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import walk_through_dir\n",
        "walk_through_dir(data_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlVaIJtFxO7a",
        "outputId": "e799e7ab-b170-4667-96c4-05f91751e9a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " There are 0 images and 2 folder at /content/10_food_classes_10_percent\n",
            " There are 0 images and 10 folder at /content/10_food_classes_10_percent/test\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/sushi\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/ramen\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/steak\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/fried_rice\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/grilled_salmon\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/pizza\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/chicken_curry\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/hamburger\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/ice_cream\n",
            " There are 250 images and 0 folder at /content/10_food_classes_10_percent/test/chicken_wings\n",
            " There are 0 images and 10 folder at /content/10_food_classes_10_percent/train\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/sushi\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/ramen\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/steak\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/fried_rice\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/grilled_salmon\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/pizza\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/chicken_curry\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/hamburger\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/ice_cream\n",
            " There are 75 images and 0 folder at /content/10_food_classes_10_percent/train/chicken_wings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=\"/content/10_food_classes_10_percent/train\"\n",
        "test_dir=\"/content/10_food_classes_10_percent/train\"\n"
      ],
      "metadata": {
        "id": "Y8GMG2izycFv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create data inputs\n",
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE=(224,224)\n",
        "train_data_10_percent= tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir\n",
        "                                                                           ,labels=\"inferred\"\n",
        "                                                                           ,label_mode=\"categorical\"\n",
        "                                                                           ,image_size=IMG_SIZE\n",
        "                                                                           ,shuffle=True\n",
        "                                                                           )\n",
        "test_data_10_percent= tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir\n",
        "                                                                          ,labels=\"inferred\"\n",
        "                                                                          ,label_mode=\"categorical\"\n",
        "                                                                          ,image_size=IMG_SIZE\n",
        "                                                                          ,shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xEdwhUjp9Rm",
        "outputId": "04366191-04d0-4d9f-d1a8-032183137c94"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 750 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_10_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gOjV5OcrEYa",
        "outputId": "8d8f9791-f718-47b5-d5ed-018aba525136"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLwu71_DrRpF",
        "outputId": "d9c0c95c-d3c4-4ad8-f88d-6944b5058f56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensorboard_callbacks(log_dir,experiment_name):\n",
        "  log_dir = log_dir + \"/\" + experiment_name+ \"/\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  return tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "LiliRdvRyTQB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Build a Transfer Learning model using keras Functional API\n",
        "\n",
        "Steps:\n",
        "1. Instantiate a pre-trained base model object by choosing the target model as [EfficientNetB0]() from `tf.keras.applications` setting the `include_top` parameter to `False` ( as we will have our own output layers)\n",
        "2. Set the base model's `trainable` attribute to `False` to freeze all of the weights in the pre-trained model\n",
        "3. Define an input layer for our model, what shape of data should our model expects.\n",
        "4. Normalize the input to our model if needed.\n",
        "5. Pass the input to the model.\n",
        "6. Pool the output of the base model into a shape compatible with output activation layer ( turn base model output tensors to same shape as label tensors). This can be done using `tf.keras.layers.GlobalAveragePooling2d()` or `tf.keras.layers.GlobalMaxPooling2D()` though the former is more common in practice.\n",
        "7. Create an output activation layer using `tf.keras.layers.Dense()` with appropriate activation function and number of neurons.\n",
        "8. Combine the input and out layers with `tf.keras.Model()`\n",
        "9. Compile the model using appropriate loss function and optimizer.\n",
        "10. Fit the model with desired number of epochs and necessary callbacks."
      ],
      "metadata": {
        "id": "MiFJAPH5rcmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instantiate a pre-trained EfficientNetB0 model disabling the top layers with include_top=False\n",
        "effnetb0_model= tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "# 2. Set the base model trainable attribute to false to freeze all of the weights in pre-trained model\n",
        "effnetb0_model.trainable= False\n",
        "# 3. Define an output layer for our model\n",
        "inputs= tf.keras.layers.Input(shape=(224,224,3),name=\"input_layer\")\n",
        "# 4. Normalize the input ( Not required as per this thread: https://github.com/tensorflow/tensorflow/issues/42506)\n",
        "\n",
        "# 5. Pass the input to the model\n",
        "x= effnetb0_model(inputs)\n",
        "\n",
        "# 6. Pool the output of the base model inot a shape compatible with output activation layer\n",
        "x= tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "# 7. Create the output activation layer\n",
        "outputs= tf.keras.layers.Dense(len(train_data_10_percent.class_names),activation=\"softmax\",name=\"output_layer\")(x)\n",
        "# 8. Combine the input and output layers\n",
        "model= tf.keras.Model(inputs= inputs\n",
        "                      ,outputs= outputs\n",
        "                      ,name=\"effnetb0_pretrained\")\n",
        "\n",
        "# 9. Compile the model\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy\n",
        "              ,optimizer=tf.keras.optimizers.Adam()\n",
        "              ,metrics=[\"accuracy\"])\n",
        "# 10. Fit the model with desired number of epochs and necessary callbacks.\n",
        "effnetb0_history= model.fit(train_data_10_percent\n",
        "                            ,steps_per_epoch=len(train_data_10_percent),\n",
        "                            validation_data=test_data_10_percent\n",
        "                            ,validation_steps=int(0.25 * len(test_data_10_percent))\n",
        "                            ,epochs=5\n",
        "                            ,callbacks=[create_tensorboard_callbacks(log_dir=\"transfer_learning\",\n",
        "                                                                     experiment_name=\"effnet_10_percent_feature_extract\")])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE91Ny2eue_W",
        "outputId": "9339611f-77c5-4ac0-daa1-c39d65d7c6c8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 92s 3s/step - loss: 1.8791 - accuracy: 0.4240 - val_loss: 1.3623 - val_accuracy: 0.7083\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 80s 3s/step - loss: 1.0994 - accuracy: 0.7573 - val_loss: 0.9296 - val_accuracy: 0.7917\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 80s 3s/step - loss: 0.7965 - accuracy: 0.8333 - val_loss: 0.6612 - val_accuracy: 0.8333\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 80s 3s/step - loss: 0.6453 - accuracy: 0.8560 - val_loss: 0.5540 - val_accuracy: 0.8906\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 79s 3s/step - loss: 0.5521 - accuracy: 0.8667 - val_loss: 0.4579 - val_accuracy: 0.8958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ef4daSYM0mYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}