{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+/VGSaMuy47gvLWs9wf2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikash119/learn_tensorflow/blob/main/learn_tf_005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing\n"
      ],
      "metadata": {
        "id": "ng00hGgV9exJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAMbWRHs8xkk",
        "outputId": "fc2e7ac3-8bf6-4dbc-b128-456986664606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeVa9a8C9skq",
        "outputId": "43ed701b-52d9-417d-c251-e5bc2fbdc790"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-14 01:07:14--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.153.128, 142.250.145.128, 173.194.79.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.153.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  1.31MB/s    in 0.4s    \n",
            "\n",
            "2023-07-14 01:07:14 (1.31 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(file):\n",
        "  \"\"\"\n",
        "    Unzips a file\n",
        "    Args:\n",
        "      file(str): Absolute file path\n",
        "    Returns\n",
        "      None\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(file)\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n"
      ],
      "metadata": {
        "id": "mdHE8X1o-H2A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_file(\"/content/nlp_getting_started.zip\")"
      ],
      "metadata": {
        "id": "gc3RACAV_Iga"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FQ3kl9WJ_NLS",
        "outputId": "40681050-34c1-447a-df46-df83ad628bb9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3dfd96d3-af34-4a07-9820-5411f3f866ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dfd96d3-af34-4a07-9820-5411f3f866ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1981c456-4b4d-44d4-a77d-be685137497c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1981c456-4b4d-44d4-a77d-be685137497c')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1981c456-4b4d-44d4-a77d-be685137497c button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3dfd96d3-af34-4a07-9820-5411f3f866ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3dfd96d3-af34-4a07-9820-5411f3f866ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmn_Yym4_pyO",
        "outputId": "9084f8c2-d3cf-436e-b02d-8159190814dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[[\"target\",\"text\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DD9Ant9kB-WH",
        "outputId": "e4761bf7-c302-41b1-fddb-74d0e9e746d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target                                               text\n",
              "0          1  Our Deeds are the Reason of this #earthquake M...\n",
              "1          1             Forest fire near La Ronge Sask. Canada\n",
              "2          1  All residents asked to 'shelter in place' are ...\n",
              "3          1  13,000 people receive #wildfires evacuation or...\n",
              "4          1  Just got sent this photo from Ruby #Alaska as ...\n",
              "...      ...                                                ...\n",
              "7608       1  Two giant cranes holding a bridge collapse int...\n",
              "7609       1  @aria_ahrary @TheTawniest The out of control w...\n",
              "7610       1  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...\n",
              "7611       1  Police investigating after an e-bike collided ...\n",
              "7612       1  The Latest: More Homes Razed by Northern Calif...\n",
              "\n",
              "[7613 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e93e75aa-5411-48e8-92c5-72e85d66dc88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>1</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>1</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>1</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>1</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>1</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e93e75aa-5411-48e8-92c5-72e85d66dc88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-87717add-6d37-4b9a-82cb-5c59fbc45b82\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87717add-6d37-4b9a-82cb-5c59fbc45b82')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-87717add-6d37-4b9a-82cb-5c59fbc45b82 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e93e75aa-5411-48e8-92c5-72e85d66dc88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e93e75aa-5411-48e8-92c5-72e85d66dc88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training samples\n",
        "import random\n",
        "\n",
        "# get a random number between the range passed as arguments to randint\n",
        "random_index = random.randint(0,len(train_df)-5)\n",
        "for row in train_df[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
        "  _,text,target = row\n",
        "  print(f\"Target : {target}\",\"(real disaster) \" if target > 0 else \"(not a real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoShOCYg_zV1",
        "outputId": "e6bf39ea-aa1e-4831-c259-aadbacfbceda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target : 1 (real disaster) \n",
            "Text:\n",
            "#pakistan#news# NANKANA SAHIB City News: Electrocuted From Our Correspondent NANKANA SAHIB: A youth was electr... http://t.co/WERK9qibVV\n",
            "\n",
            "---\n",
            "\n",
            "Target : 0 (not a real disaster)\n",
            "Text:\n",
            "God damn it!!! I electrocuted myself ??\n",
            "\n",
            "---\n",
            "\n",
            "Target : 1 (real disaster) \n",
            "Text:\n",
            "Watching a man electrocuted on the roof of #mumbailocals is definitely a lesson.. People please learn!! #lessonforlife #marinelines #mumbai\n",
            "\n",
            "---\n",
            "\n",
            "Target : 1 (real disaster) \n",
            "Text:\n",
            "Worked in factory pressing designs onto T-shirts was electrocuted \n",
            "d/t faulty ground. Boss docked my pay while I was at ER #WorstSummerJob\n",
            "\n",
            "---\n",
            "\n",
            "Target : 0 (not a real disaster)\n",
            "Text:\n",
            "Elsa is gonna end up getting electrocuted. She's gonna end up like that cat from christmas vacation.\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the data into train and test"
      ],
      "metadata": {
        "id": "tjH7CkyTDUTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df[\"text\"]\n",
        "                                                                           ,train_df[\"target\"]\n",
        "                                                                           ,test_size=0.2\n",
        "                                                                           ,random_state=42)\n",
        "\n",
        "len(train_sentences),len(val_sentences),len(train_labels),len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VRBFeM6AfpU",
        "outputId": "1718f66b-01a7-4d2e-ed71-9aa38d91acfa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6090, 1523, 6090, 1523)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert text to numbers also known as **numericalization**\n",
        "In NLP there are two main concepts for turning text to numbers\n",
        "* Tokenization\n",
        "* Embeddings\n",
        "\n",
        "**Tokenization** - is straight mapping of a word or a character or a sub-word to a numerical value. There are 3 main level of tokenization:\n",
        "  * Character level tokenization\n",
        "  * Word level tokenization\n",
        "  * Sub-word level tokenization\n",
        "\n",
        "**Embeddings** - An embedding is a representation of natural language which can be learned. These are represented as feature vectors\n",
        "  * Create your own embedding - Once the text has been converted to numbers, we can put it through an embedding layer and an embedding re-presentation will be learnt during model training\n",
        "  * Re-use pretrained embedding - Many pre-trained embedding exist online."
      ],
      "metadata": {
        "id": "9YcxHQTiIY_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n",
        "To tokenize our sentences, we will use the helpful pre-processing layer `tf.keras.layers.experimental.preprocessing.TextVectorization`"
      ],
      "metadata": {
        "id": "7CYHyA3HMLB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "text_vectorizer = layers.TextVectorization(max_tokens=None\n",
        "                                           ,standardize=\"lower_and_strip_punctuation\"\n",
        "                                           ,split=\"whitespace\"\n",
        "                                           ,ngrams=None\n",
        "                                           ,output_mode=\"int\"\n",
        "                                           ,output_sequence_length=None)"
      ],
      "metadata": {
        "id": "S8uZjECUEMNH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avg number of words in a tweet\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VlxO_SDOKLu",
        "outputId": "d2fa2e54-da33-4636-e179-96c0b17a0d04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length=10000\n",
        "max_length=15\n",
        "text_vectorizer = layers.TextVectorization(max_tokens=max_vocab_length\n",
        "                                           ,output_mode=\"int\"\n",
        "                                           ,output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "BldqlPbNObke"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt([train_sentences])"
      ],
      "metadata": {
        "id": "SCV3iwAOXJRO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\" Raw text : {random_sentence}\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW4av-l4PWDM",
        "outputId": "19e4b176-c9db-4b12-b6ff-065f07a0b0aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Raw text : Christian Attacked by Muslims at the Temple Mount after Waving Israeli Flag via Pamela Geller - ... http://t.co/a6wmbnR51S\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1035,  460,   18, 1162,   17,    2,  946, 1081,   38, 1221,  737,\n",
              "         920,   51, 1158, 1279]])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab=text_vectorizer.get_vocabulary()\n",
        "print(f\" Top 5 common words :{words_in_vocab[:5]}\")\n",
        "print(f\" Top 5 un-common words :{words_in_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P7XTBzOW9cU",
        "outputId": "c68d9fc1-0769-4868-c56f-dce2097ec81e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Top 5 common words :['', '[UNK]', 'the', 'a', 'in']\n",
            " Top 5 un-common words :['mideast', 'middleeasteye', 'midday', 'microwave', 'microphone']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and Embedding using Embedding layer.\n",
        "\n",
        "We can see what an embedding looks like by using `tf.keras.layers.Embedding`"
      ],
      "metadata": {
        "id": "ql5zjif-b0Et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length\n",
        "                             ,output_dim=128\n",
        "                             ,embeddings_initializer=\"uniform\"\n",
        "                             ,input_length=max_length\n",
        "                             ,name=\"embedding_1\")"
      ],
      "metadata": {
        "id": "n440_1N8bXDv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_sentence= train_sentences[random.randint(0,len(train_sentences))]\n",
        "print(f\"random sentence :{random_sentence}\")\n",
        "print(f\"Vectorized Version :{text_vectorizer(random_sentence)}\")\n",
        "sentence_embeddings = embedding(text_vectorizer(random_sentence))\n",
        "print(f\"Embeddings : {sentence_embeddings}\")\n",
        "print(f\"Embeddings Shape: {sentence_embeddings.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5248oQJjcsSS",
        "outputId": "46e489e4-0bdc-449a-9de2-c403aedfa1de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random sentence :@LegacyOfTheSith @SagaciousSaber @Lordofbetrayal Moved in a crescent formation small trails of dust left in their wake as they moved.\n",
            "Vectorized Version :[   1 8112    1 1878    4    3    1 5092 1481 6734    6  516  510    4\n",
            "  108]\n",
            "Embeddings : [[ 2.9161464e-02  1.8865492e-02 -3.6466867e-05 ... -2.3016680e-02\n",
            "   9.7699389e-03 -4.4247475e-02]\n",
            " [ 3.1892013e-02 -2.4341131e-02 -4.0013552e-02 ... -2.3699105e-02\n",
            "  -3.6830138e-02  3.5936389e-02]\n",
            " [ 2.9161464e-02  1.8865492e-02 -3.6466867e-05 ... -2.3016680e-02\n",
            "   9.7699389e-03 -4.4247475e-02]\n",
            " ...\n",
            " [ 3.8249765e-02  9.1676712e-03  1.3392679e-03 ...  4.3154303e-02\n",
            "   3.6989454e-02 -2.9325796e-02]\n",
            " [-4.7078978e-02 -4.2669784e-02 -3.7726652e-02 ...  4.2303037e-02\n",
            "  -1.3202764e-02 -2.2031629e-02]\n",
            " [-3.5100151e-02 -2.9660797e-02  4.6774600e-02 ...  1.6073473e-03\n",
            "  -4.0192176e-02 -1.0974646e-02]]\n",
            "Embeddings Shape: (15, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_embeddings[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQrjqZOrdZRq",
        "outputId": "ee057641-f7d1-4493-dab3-f46944ac48d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 2.91614644e-02,  1.88654922e-02, -3.64668667e-05,  4.20862772e-02,\n",
              "        2.35883631e-02,  7.48214871e-03,  5.62139601e-03, -2.26333030e-02,\n",
              "        3.86997312e-03, -4.94790934e-02, -8.82618502e-03, -5.04351780e-03,\n",
              "       -7.60961697e-03,  3.86091359e-02,  7.24934414e-03, -3.44217941e-03,\n",
              "        2.80272402e-02,  3.57330702e-02,  1.58400200e-02,  3.58368419e-02,\n",
              "        3.51726748e-02,  1.44314021e-04, -1.91688072e-02, -4.58919406e-02,\n",
              "        4.45633419e-02, -4.35164459e-02,  2.26111896e-02,  4.98926751e-02,\n",
              "       -3.64930518e-02,  1.59620084e-02,  6.82048872e-03, -4.25522104e-02,\n",
              "        2.68998183e-02,  3.00740488e-02,  2.34864838e-02,  2.96656750e-02,\n",
              "        3.89944576e-02, -6.62311167e-03,  3.74062546e-02,  3.79142873e-02,\n",
              "       -1.37289278e-02, -1.36686563e-02, -3.57804783e-02,  3.75675075e-02,\n",
              "       -1.29755624e-02, -3.93210426e-02, -1.72512643e-02,  4.78843935e-02,\n",
              "        4.85538878e-02,  2.92403586e-02, -2.61822585e-02,  3.05198915e-02,\n",
              "       -2.39804387e-02, -2.23031174e-02, -7.62844086e-03,  3.99522856e-03,\n",
              "        2.69121416e-02, -1.54650435e-02, -5.26629388e-04, -2.56202575e-02,\n",
              "        1.38903968e-02,  1.01550110e-02,  3.70358266e-02,  1.35138072e-02,\n",
              "        2.81463005e-02,  2.48735286e-02,  3.89107503e-02, -4.15274277e-02,\n",
              "       -3.96516696e-02, -4.55390476e-02, -7.91733339e-03,  2.56113149e-02,\n",
              "        1.65037550e-02,  1.53031610e-02,  3.46112512e-02,  4.53456901e-02,\n",
              "       -4.20735851e-02, -1.34798065e-02,  3.69300283e-02,  3.54866274e-02,\n",
              "        1.72729418e-03,  4.66498174e-02,  9.59085301e-03,  3.67912762e-02,\n",
              "        4.76154946e-02, -3.56928334e-02,  1.62758492e-02, -2.83415206e-02,\n",
              "       -3.64217050e-02, -1.36639252e-02, -2.26059444e-02,  1.56270154e-02,\n",
              "       -4.81961034e-02,  4.49932329e-02, -1.09332204e-02,  4.38892581e-02,\n",
              "       -4.62943316e-03, -2.73541454e-02, -3.43861468e-02,  1.41459145e-02,\n",
              "        2.11330913e-02, -4.04636972e-02,  1.71249397e-02, -4.18661125e-02,\n",
              "       -6.25381619e-03,  4.27716486e-02,  2.10785866e-03,  4.08443063e-03,\n",
              "        4.78999875e-02,  3.49462666e-02, -4.33707237e-03, -3.34348083e-02,\n",
              "        1.73928589e-03, -2.82389056e-02,  2.75248177e-02,  2.36875303e-02,\n",
              "        2.57551931e-02,  4.62175272e-02, -2.33566519e-02, -3.99014242e-02,\n",
              "        7.63374567e-03,  1.26105547e-03, -3.75568047e-02,  1.64151676e-02,\n",
              "        4.80430201e-03, -2.30166800e-02,  9.76993889e-03, -4.42474745e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling a text dataset\n",
        "We will be building a series of different models, each as its own experimient.\n",
        "More specifically, we will build the following\n",
        "1. **Model 0**: Naive Bayes (baseline)\n",
        "2. **Model 1**: Feed forward network model (dense model)\n",
        "3. **Model 2**: LSTM model\n",
        "4. **Model 3**: GRU model\n",
        "5. **Model 4**: Bidirectional LSTM model\n",
        "6. **Model 5**: 1D Convolutional Neural Network\n",
        "7. **Model 6**: Tensorflow Hub Pretrained Feature Extractor\n",
        "8. **Model 7**: Same as model 6 with 10% of training data"
      ],
      "metadata": {
        "id": "SgkiiUin088y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Baseline"
      ],
      "metadata": {
        "id": "qWaHWVifBuhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()) # convert words to numbers using tfidf\n",
        "    ,(\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences,train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "s85GoDNKeO4h",
        "outputId": "fa3bf268-0cbc-47d5-f34f-4a80d757e2aa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score = model_0.score(val_sentences,val_labels)\n",
        "print(f\" Our baseline model achieves an accuracy of {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZaEVQ1OCmd0",
        "outputId": "e2051d78-7517-4757-e103-54679eab3e2d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Our baseline model achieves an accuracy of 79.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmZ4DUd2DmI6",
        "outputId": "447962b7-62e1-41ef-823e-71d5aca8de24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a evaluation function for all our model experiments. Our evaluation function takes _ground truths_, _predicted values_ and returns\n",
        "1. Accuracy\n",
        "2. Precision\n",
        "3. Recall\n",
        "4. F1-score"
      ],
      "metadata": {
        "id": "LUzkoV98EL_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to evaluation accuracy, precision, recall, f1-score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def evaluate_model(y_true,y_pred):\n",
        "  \"\"\"\n",
        "    Calculate model accuracy, precision, recall and f1-score of a binary classification model.\n",
        "    Args:\n",
        "      y_true: true labels in the form of 1D array\n",
        "      y_pred: predicted labels in the form of 1D array\n",
        "\n",
        "    Returns:\n",
        "      eval_dict(dict): A dictionary of accuracy, precision, recall and f1-score\n",
        "      {\n",
        "        \"accuracy\":float\n",
        "        ,\"precision\":float\n",
        "        ,\"recall\":float\n",
        "        \"f1\":float\n",
        "      }\n",
        "  \"\"\"\n",
        "\n",
        "  # calculate the model accuracy\n",
        "  model_accuracy = accuracy_score(y_true,y_pred) * 100\n",
        "\n",
        "  # calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall,model_f1, _ = precision_recall_fscore_support(y_true,y_pred,average=\"weighted\")\n",
        "\n",
        "  model_results = {\n",
        "        \"accuracy\":model_accuracy\n",
        "        ,\"precision\":model_precision\n",
        "        ,\"recall\":model_recall\n",
        "        ,\"f1\":model_f1\n",
        "      }\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "hHJdQUlVD7fn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = evaluate_model(y_true=val_labels\n",
        "                                  ,y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnrEFMHlHb55",
        "outputId": "3156c3ba-641b-4566-86b9-35eee7cfa7ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.97373604727511,\n",
              " 'precision': 0.8102693639254774,\n",
              " 'recall': 0.7997373604727511,\n",
              " 'f1': 0.7932459520374361}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: A simple Dense model\n",
        "The \"first\" model we're going to build is a single layer dense model.\n",
        "\n",
        "It'll take our\n",
        "1. text and labels as input,\n",
        "2. tokenize the text,\n",
        "3. create an embedding,\n",
        "4. find the average of the embedding (Using Global Average Pooling)\n",
        "5. and then pass the average through a fully connected layer with one input and a sigmoid activation.\n",
        "```\n",
        " WHEN IN DOUBT, CODE IT OUT\n",
        "```\n",
        "As we'll be creating a number of experiments, we will have to track the experiments using `tensorboard`"
      ],
      "metadata": {
        "id": "e0piijFJIhsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#1 Instantiate a Keras tensor\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
        "#2 tokenize the input\n",
        "x= text_vectorizer(inputs)\n",
        "#3 create embedding\n",
        "x= embedding(x)\n",
        "#4 find the avg of the embedding using Global Average Pooling\n",
        "x= layers.GlobalAveragePooling1D()(x)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")\n",
        "\n",
        "model_1.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                ,optimizer=tf.keras.optimizers.Adam()\n",
        "                ,metrics=[\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXvO4K72Hk6v",
        "outputId": "982c3720-4d6a-479c-c6a2-0bd53062475b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "def create_tensorboard_callback(dir_name,experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  return tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "GfXQZdeAUtZJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = \"model_logs\"\n",
        "model_1.fit(train_sentences\n",
        "            ,train_labels\n",
        "            ,validation_data=(val_sentences,val_labels)\n",
        "            ,epochs=5\n",
        "            ,callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_1_dense\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgNLkQw1Pg4h",
        "outputId": "b80cae7e-dae9-4ab1-86e7-e2743f9432a6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 5s 21ms/step - loss: 0.6229 - accuracy: 0.6854 - val_loss: 0.5431 - val_accuracy: 0.7597\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 4s 21ms/step - loss: 0.4554 - accuracy: 0.8107 - val_loss: 0.4644 - val_accuracy: 0.8004\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 4s 18ms/step - loss: 0.3554 - accuracy: 0.8578 - val_loss: 0.4462 - val_accuracy: 0.8050\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 3s 17ms/step - loss: 0.2888 - accuracy: 0.8893 - val_loss: 0.4474 - val_accuracy: 0.8037\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 5s 28ms/step - loss: 0.2398 - accuracy: 0.9133 - val_loss: 0.4611 - val_accuracy: 0.7945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7db0ec889ae0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model_1.evaluate(val_sentences,val_labels)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHDZYUmXYVmA",
        "outputId": "246a6963-73c3-490e-d4be-0f9f7132ffc2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4611169099807739, 0.794484555721283]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBosyShlYyOB",
        "outputId": "71b4b3c9-86a3-425b-f008-b4065cdb446b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[-0.05452561, -0.03635808, -0.00230713, ...,  0.05692822,\n",
              "          0.04471098,  0.0415373 ],\n",
              "        [ 0.02390426,  0.01477811, -0.00421123, ..., -0.01807669,\n",
              "          0.01550504, -0.0399521 ],\n",
              "        [-0.05887538, -0.04896552,  0.02923229, ...,  0.00063005,\n",
              "         -0.01781445, -0.03082237],\n",
              "        ...,\n",
              "        [-0.06085011, -0.02155629, -0.04376039, ...,  0.06881609,\n",
              "          0.0990495 ,  0.06372061],\n",
              "        [-0.06166863, -0.06867801, -0.05757005, ..., -0.00621877,\n",
              "          0.06546495,  0.09230724],\n",
              "        [-0.0882747 , -0.10806379, -0.04411944, ...,  0.05515028,\n",
              "          0.01534563,  0.10577388]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yes | tensorboard dev upload --logdir ./model_logs \\\n",
        " --name=\"First deep model on text data\" \\\n",
        " --description=\"Trying a dense model with text data\" \\\n",
        " --one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ittq5n7IY7qf",
        "outputId": "6af301db-9f44-48ac-dcdb-1dc8781a4768"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-14 01:08:41.616910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./model_logs\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) \n",
            "To sign in with the TensorBoard uploader:\n",
            "\n",
            "1. On your computer or phone, visit:\n",
            "\n",
            "   https://www.google.com/device\n",
            "\n",
            "2. Sign in with your Google account, then enter:\n",
            "\n",
            "   ZFMC-PLJV\n",
            "\n",
            "\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/UgH03o4WTQ2EDwndJYVntg/\n",
            "\n",
            "\u001b[1m[2023-07-14T01:09:17]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2023-07-14T01:09:18]\u001b[0m Total uploaded: 30 scalars, 0 tensors, 1 binary objects (62.2 kB)\n",
            "\u001b[1m[2023-07-14T01:09:18]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/UgH03o4WTQ2EDwndJYVntg/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab),words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWqdgqfMZxz5",
        "outputId": "fd35618e-774d-459d-9e2c-d4b5735e1d7a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'i', 'and', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VdeEZ3v380N",
        "outputId": "773a35b0-fe4c-4ab2-a88b-4ae9fd94137c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "embed_weights= model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IFiygYG4dTg",
        "outputId": "8f978dfe-39fc-46f2-e4e2-5ce9c98deaa9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9QjInngl5YF7",
        "outputId": "8d50e287-419d-49d7-bc8a-372c84a70d43"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5c20e7fa-9ca2-43d5-87a6-77c856ea0fa9\", \"vectors.tsv\", 15396830)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3bcf720a-53e1-4532-9fbc-7ae754e712b6\", \"metadata.tsv\", 80637)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Neural Network\n",
        "\n",
        "For our next series of modelling expermients, we'll explore special kind of neural network called **Recurrent Neural Network**\n",
        "\n",
        "The premise of RNN is simple: use information from the past to help you with the future. In other words, take an input(`X`) and compute and output(`y`) based on all previous inputs.\n",
        "\n",
        "Variants of RNN\n",
        "1. LSTM ( Long short-term memory cells)\n",
        "2. GRU (Gated Recurrent Units)\n",
        "3. Bidirectional RNN (passes forward and backward along a sequence, left to right and right to left)\n"
      ],
      "metadata": {
        "id": "buLNZIxM7jNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 : LSTM\n",
        "Our model structure\n",
        "```\n",
        "Input -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```"
      ],
      "metadata": {
        "id": "Y4dQN7Sy-OcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length\n",
        "                                     ,output_dim=128\n",
        "                                     ,embeddings_initializer=\"uniform\"\n",
        "                                     ,input_length=max_length\n",
        "                                     ,name=\"embedding_2\")\n",
        "\n",
        "# Create LSTM model\n",
        "inputs= layers.Input(shape=(1,),dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= model_2_embedding(x)\n",
        "print(x.shape)\n",
        "x= layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_2= tf.keras.Model(inputs,outputs,name=\"model_2_LSTM\")\n",
        "\n",
        "model_2.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                ,optimizer=tf.keras.optimizers.Adam()\n",
        "                ,metrics=[\"accuracy\"]\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbk9-4v36s2M",
        "outputId": "3f7ad527-1572-40f5-8315-0ba888971e77"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zynFYwf-a_J",
        "outputId": "b4bcafbf-d95e-45ac-c0e9-418de1042937"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_2 = model_2.fit(train_sentences\n",
        "                        ,train_labels\n",
        "                        ,validation_data=(val_sentences,val_labels)\n",
        "                        ,callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_2\")]\n",
        "                        ,epochs=5\n",
        "                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dNp0VpB-zFm",
        "outputId": "d9dd2352-d5fc-42a8-920c-dcae45b89f27"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 10s 41ms/step - loss: 0.5254 - accuracy: 0.7392 - val_loss: 0.4414 - val_accuracy: 0.8004\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 7s 35ms/step - loss: 0.3150 - accuracy: 0.8713 - val_loss: 0.4666 - val_accuracy: 0.7958\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 7s 36ms/step - loss: 0.2095 - accuracy: 0.9233 - val_loss: 0.6184 - val_accuracy: 0.7781\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 7s 37ms/step - loss: 0.1456 - accuracy: 0.9524 - val_loss: 0.7035 - val_accuracy: 0.7525\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 6s 34ms/step - loss: 0.1019 - accuracy: 0.9644 - val_loss: 0.9522 - val_accuracy: 0.7531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs=model_2.predict(val_sentences)\n",
        "y_pred = tf.squeeze(tf.round(y_pred_probs))\n",
        "y_pred.shape,val_labels.shape\n",
        "model_2_evaluation = evaluate_model(y_true=val_labels\n",
        "                                    ,y_pred=y_pred)\n",
        "model_2_evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr80XRrd_hzB",
        "outputId": "507f0ec9-408d-4ca6-c416-addf3ad860ce"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.31188443860802,\n",
              " 'precision': 0.7588463865739015,\n",
              " 'recall': 0.7531188443860801,\n",
              " 'f1': 0.7543032959000442}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: GRU ( Gated Rectilinear Units).\n",
        "The architecture of the GRU-powered model will follow the same structure.\n",
        "```\n",
        "Input(text) -> Tokenize -> Embedding -> Layers -> Output ( Label Probabilities)\n",
        "```"
      ],
      "metadata": {
        "id": "sul9LU_lBQBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_3_embedding= layers.Embedding(input_dim=max_vocab_length\n",
        "                                    ,output_dim=128\n",
        "                                    ,input_length=max_length\n",
        "                                    ,embeddings_initializer=\"uniform\"\n",
        "                                    ,name=\"embedding_3\"\n",
        "                                    )\n",
        "\n",
        "inputs= layers.Input(shape=(1,),dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= model_3_embedding(x)\n",
        "print(x.shape)\n",
        "x= layers.GRU(64)(x)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_3= tf.keras.Model(inputs,outputs,name=\"model_3_GRU\")\n",
        "\n",
        "model_3.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                ,optimizer=tf.keras.optimizers.Adam()\n",
        "                ,metrics=[\"accuracy\"]\n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTzXwVMA__oI",
        "outputId": "9044def4-836b-42d6-a622-2417ffb94cea"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9fYRBYAEuV1",
        "outputId": "cb73effc-ebf7-4b46-ab44-6e167bca59c4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_3 = model_3.fit(train_sentences\n",
        "                        ,train_labels\n",
        "                        ,validation_data=(val_sentences,val_labels)\n",
        "                        ,epochs=5\n",
        "                        ,callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_3\")]\n",
        "                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzzJaUTKEwtD",
        "outputId": "9e122a73-1b1b-4139-99d1-8cd141c83e15"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 10s 34ms/step - loss: 0.5487 - accuracy: 0.7112 - val_loss: 0.4522 - val_accuracy: 0.7958\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 7s 35ms/step - loss: 0.3224 - accuracy: 0.8649 - val_loss: 0.4683 - val_accuracy: 0.8024\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 6s 32ms/step - loss: 0.2084 - accuracy: 0.9202 - val_loss: 0.5876 - val_accuracy: 0.7853\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 7s 35ms/step - loss: 0.1439 - accuracy: 0.9522 - val_loss: 0.6489 - val_accuracy: 0.7663\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 6s 32ms/step - loss: 0.1042 - accuracy: 0.9672 - val_loss: 0.8178 - val_accuracy: 0.7544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs= model_3.predict(val_sentences)\n",
        "y_pred = tf.squeeze(tf.round(y_pred_probs))\n",
        "y_pred.shape,val_labels.shape\n",
        "\n",
        "model_3_metrics= evaluate_model(y_true=val_labels,y_pred=y_pred)\n",
        "model_3_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoyeKxWRFFU9",
        "outputId": "ab0f1c57-7ca5-447a-f47c-97c580302b32"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.44320420223244,\n",
              " 'precision': 0.7572309516355729,\n",
              " 'recall': 0.7544320420223244,\n",
              " 'f1': 0.7552576773239887}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4: Bidirectional RNN Model\n",
        "\n",
        "```\n",
        "Input(text) -> Tokenize -> Embedding -> Layers -> Output(Label Probabilities)\n",
        "```"
      ],
      "metadata": {
        "id": "eV0Ld8oaFsFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_4_embedding= layers.Embedding(input_dim=max_vocab_length\n",
        "                                    ,output_dim=128\n",
        "                                    ,embeddings_initializer=\"uniform\"\n",
        "                                    ,input_length=max_length\n",
        "                                    ,name=\"embeddding_4\")\n",
        "\n",
        "inputs= layers.Input(shape=(1,),dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= model_4_embedding(x)\n",
        "print(x.shape)\n",
        "x= layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs,outputs,name=\"model_4_Bi-directional\")\n",
        "\n",
        "model_4.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                ,optimizer=tf.keras.optimizers.Adam()\n",
        "                ,metrics=[\"accuracy\"]\n",
        "                )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8yJQPhPFl-G",
        "outputId": "fcb6a990-5b4d-44d9-9b96-f38769f36309"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCsSBvndPMgy",
        "outputId": "b348a63a-aa23-4ef5-8c8a-936712f9069c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bi-directional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embeddding_4 (Embedding)    (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_4 = model_4.fit(train_sentences\n",
        "                        ,train_labels\n",
        "                        ,validation_data=(val_sentences,val_labels)\n",
        "                        ,epochs=5\n",
        "                        ,callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_4\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iSVLPeMPVj_",
        "outputId": "21316ae0-5123-4501-914a-c1b6d33c9ec0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 15s 47ms/step - loss: 0.5192 - accuracy: 0.7427 - val_loss: 0.4428 - val_accuracy: 0.8017\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 8s 41ms/step - loss: 0.3100 - accuracy: 0.8729 - val_loss: 0.4784 - val_accuracy: 0.8004\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 9s 45ms/step - loss: 0.1995 - accuracy: 0.9282 - val_loss: 0.5787 - val_accuracy: 0.7840\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 8s 40ms/step - loss: 0.1376 - accuracy: 0.9548 - val_loss: 0.6999 - val_accuracy: 0.7643\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 8s 43ms/step - loss: 0.1008 - accuracy: 0.9657 - val_loss: 0.8012 - val_accuracy: 0.7603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs= model_4.predict(val_sentences)\n",
        "y_pred= tf.squeeze(tf.round(y_pred_probs))\n",
        "y_pred.shape,val_labels.shape\n",
        "model_4_metrics = evaluate_model(y_true=val_labels,y_pred=y_pred)\n",
        "model_4_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Me7zjaPnsk",
        "outputId": "bed9d499-ffdc-46b4-e260-76f4a0121b6b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 1s 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.03414313854235,\n",
              " 'precision': 0.7646688069908305,\n",
              " 'recall': 0.7603414313854235,\n",
              " 'f1': 0.7613655342090655}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5: Convolutional Neural Networks for Text\n",
        "The basic principles are:\n",
        "1. 1-dimensional convolving filters are used as ngram detector, each filter specializing in a closely-related family of ngrams.\n",
        "2. Max-pooling over time extracts the relevant ngrams for making a decision.\n",
        "3. The rest of the network classifies the text based on this information."
      ],
      "metadata": {
        "id": "En716bzVSRZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_5_embedding= layers.Embedding(input_dim=max_vocab_length\n",
        "                                    ,output_dim=128\n",
        "                                    ,embeddings_initializer=\"uniform\"\n",
        "                                    ,input_length=max_length\n",
        "                                    ,name=\"embedding_5\")\n",
        "\n",
        "inputs= layers.Input(shape=(1,),dtype=\"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x= model_5_embedding(x)\n",
        "print(x.shape)\n",
        "x= layers.Conv1D(filters=32,kernel_size=5,activation=\"relu\")(x)\n",
        "x= layers.GlobalMaxPool1D()(x)\n",
        "outputs= layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs,outputs,name=\"model_5_Conv1D\")\n",
        "\n",
        "model_5.compile(loss=tf.keras.losses.binary_crossentropy\n",
        "                ,optimizer=tf.keras.optimizers.Adam()\n",
        "                ,metrics=[\"accuracy\"]\n",
        "                )\n",
        "\n",
        "model_5.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlCt3V12QL3z",
        "outputId": "450a570b-6bb7-45a6-868c-6ffeff48520b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 32)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,300,545\n",
            "Trainable params: 1,300,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_5 = model_5.fit(train_sentences\n",
        "                       ,train_labels\n",
        "                       ,validation_data=(val_sentences,val_labels)\n",
        "                       ,epochs=5\n",
        "                       ,callbacks=[(create_tensorboard_callback(dir_name=SAVE_DIR,experiment_name=\"model_5\"))]\n",
        "                       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yryOP_vbYIGV",
        "outputId": "976358ac-0e80-4ff3-89ba-539f28cdd7dc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 6s 23ms/step - loss: 0.5724 - accuracy: 0.7128 - val_loss: 0.4616 - val_accuracy: 0.7951\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 4s 22ms/step - loss: 0.3441 - accuracy: 0.8565 - val_loss: 0.4694 - val_accuracy: 0.7912\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 4s 19ms/step - loss: 0.2093 - accuracy: 0.9268 - val_loss: 0.5541 - val_accuracy: 0.7807\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 4s 20ms/step - loss: 0.1324 - accuracy: 0.9560 - val_loss: 0.6186 - val_accuracy: 0.7866\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 5s 24ms/step - loss: 0.0903 - accuracy: 0.9722 - val_loss: 0.6846 - val_accuracy: 0.7649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs= model_5.predict(val_sentences)\n",
        "y_pred = tf.squeeze(tf.round(y_pred_probs))\n",
        "y_pred.shape, val_labels.shape\n",
        "\n",
        "model_5_metrics = evaluate_model(y_true=val_labels,y_pred=y_pred)\n",
        "model_5_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWDcCF88YfLy",
        "outputId": "8f70a742-726c-4041-ebdf-16dfacccd107"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.49376231122784,\n",
              " 'precision': 0.764244436407231,\n",
              " 'recall': 0.7649376231122784,\n",
              " 'f1': 0.7644827804078497}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1i0hsntZJvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}